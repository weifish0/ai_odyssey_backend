from fastapi import FastAPI, HTTPException, Depends, status, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
import httpx
import os
import uuid
import jwt
import bcrypt
from datetime import datetime, timedelta, timezone
from dotenv import load_dotenv
import logging
import random
from openai import OpenAI
import hashlib
import aiofiles
from fastapi.staticfiles import StaticFiles
import json
from google import genai
from fastapi.encoders import jsonable_encoder
from contextlib import asynccontextmanager
import tensorflow as tf
from image_classification import ImageClassificationModel

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- å½±åƒè¾¨è­˜ ---
# 1. ç”¨æ–¼å­˜æ”¾é å…ˆè¼‰å…¥çš„ MobileNet åŸºç¤æ¨¡å‹
GLOBAL_MOBILENET = None
# 2. ç”¨æ–¼ç·©å­˜ä¸åŒç”¨æˆ¶çš„å·²è¨“ç·´æ¨¡å‹ï¼Œé¿å…é‡è¤‡å¾ç¡¬ç¢Ÿè®€å–
USER_MODELS = {} 

# --- API ç”Ÿå‘½é€±æœŸäº‹ä»¶ ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    # åœ¨æ‡‰ç”¨ç¨‹å¼å•Ÿå‹•æ™‚åŸ·è¡Œçš„ç¨‹å¼ç¢¼
    global GLOBAL_MOBILENET
    logger.info("ä¼ºæœå™¨å•Ÿå‹•ï¼Œé–‹å§‹è¼‰å…¥ MobileNet V3 åŸºç¤æ¨¡å‹...")
    try:
        GLOBAL_MOBILENET = tf.keras.applications.MobileNetV3Small(
            input_shape=(224, 224, 3),
            include_top=False,
            weights='imagenet',
            pooling='avg'
        )
        GLOBAL_MOBILENET.trainable = False
        # é ç†±æ¨¡å‹
        dummy_input = tf.zeros((1, 224, 224, 3))
        _ = GLOBAL_MOBILENET(dummy_input)
        logger.info("âœ… MobileNet V3 åŸºç¤æ¨¡å‹è¼‰å…¥æˆåŠŸä¸¦å·²è¨­å®šç‚ºå…¨åŸŸå…±ç”¨ï¼")
    except Exception as e:
        logger.error(f"âŒ è¼‰å…¥ MobileNet åŸºç¤æ¨¡å‹å¤±æ•—: {e}")
        GLOBAL_MOBILENET = None
    
    # å•Ÿå‹•å®šæœŸæ¸…ç†ä»»å‹™
    import asyncio
    cleanup_task = asyncio.create_task(cleanup_expired_tokens_task())
    logger.info("âœ… å®šæœŸæ¸…ç†éæœŸ token ä»»å‹™å·²å•Ÿå‹•")
    
    yield
    
    # åœ¨æ‡‰ç”¨ç¨‹å¼é—œé–‰æ™‚åŸ·è¡Œçš„ç¨‹å¼ç¢¼
    cleanup_task.cancel()
    try:
        await cleanup_task
    except asyncio.CancelledError:
        pass
    logger.info("ä¼ºæœå™¨æ­£åœ¨é—œé–‰...")

app = FastAPI(
    title="AI Odyssey Backend API",
    description="AI å­¸ç¿’éŠæˆ²å¹³å°å¾Œç«¯ API",
    version="2.0.0",
    lifespan=lifespan
)

# è¨­å®š CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å®‰å…¨è¨­å®š
security = HTTPBearer()
SECRET_KEY = os.getenv("SECRET_KEY", "your-secret-key-change-in-production")
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 300

# å°å…¥ SQLite è³‡æ–™åº«ç®¡ç†å™¨
from database import db_manager

# åˆå§‹åŒ–è³‡æ–™åº«ï¼ˆåœ¨æ‡‰ç”¨ç¨‹å¼å•Ÿå‹•æ™‚æœƒè‡ªå‹•å‰µå»ºè¡¨æ ¼ï¼‰
logger.info("æ­£åœ¨åˆå§‹åŒ– SQLite è³‡æ–™åº«...")

# NCHC API è¨­å®š
NCHC_API_BASE_URL = "https://portal.genai.nchc.org.tw/api/v1"
API_KEY = os.getenv("NCHC_API_KEY")

if not API_KEY:
    logger.warning("NCHC_API_KEY ç’°å¢ƒè®Šæ•¸æœªè¨­å®š")

# OpenAI API è¨­å®š
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    logger.warning("OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸æœªè¨­å®š")
else:
    openai_client = OpenAI(api_key=OPENAI_API_KEY)

# Google Gemini API è¨­å®š
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    logger.warning("GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸æœªè¨­å®š")
else:
    client = genai.Client(api_key=GEMINI_API_KEY)

# è¼‰å…¥ system prompts
def load_system_prompts():
    """è¼‰å…¥ system prompts å¾ JSON æª”æ¡ˆ"""
    try:
        with open("system_prompts.json", "r", encoding="utf-8") as f:
            data = json.load(f)
            return data.get("prompts", [])
    except FileNotFoundError:
        logger.warning("system_prompts.json æª”æ¡ˆæœªæ‰¾åˆ°ï¼Œä½¿ç”¨é è¨­ prompt")
        return []
    except json.JSONDecodeError:
        logger.error("system_prompts.json æª”æ¡ˆæ ¼å¼éŒ¯èª¤")
        return []

# è¼‰å…¥ prompts
system_prompts = load_system_prompts()

# ç¢ºä¿ static/images è³‡æ–™å¤¾å­˜åœ¨
STATIC_IMAGES_DIR = "static/images"
os.makedirs(STATIC_IMAGES_DIR, exist_ok=True)

# å®šæœŸæ¸…ç†éæœŸ token çš„ä»»å‹™
async def cleanup_expired_tokens_task():
    """å®šæœŸæ¸…ç†éæœŸçš„ token å’Œæœƒè©±"""
    import asyncio
    while True:
        try:
            await asyncio.sleep(3600)  # æ¯å°æ™‚åŸ·è¡Œä¸€æ¬¡
            db_manager.cleanup_expired_tokens()
        except Exception as e:
            logger.error(f"æ¸…ç†éæœŸ token ä»»å‹™å¤±æ•—: {e}")

# è¨­å®šéœæ…‹æª”æ¡ˆæœå‹™ (åœ¨è³‡æ–™å¤¾å‰µå»ºä¹‹å¾Œ)
app.mount("/static", StaticFiles(directory="static"), name="static")

# Pydantic æ¨¡å‹ - èªè­‰ç›¸é—œ
class UserRegister(BaseModel):
    username: str = Field(..., description="ä½¿ç”¨è€…åç¨±")
    password: str = Field(..., description="å¯†ç¢¼")

class UserLogin(BaseModel):
    username: str = Field(..., description="ä½¿ç”¨è€…åç¨±")
    password: str = Field(..., description="å¯†ç¢¼")

class User(BaseModel):
    id: str = Field(..., example="550e8400-e29b-41d4-a716-446655440000")
    username: str = Field(..., example="æ¢éšªå®¶å°æ˜")
    money: int = Field(500, example=500, description="éŠæˆ²é‡‘å¹£")

# Pydantic æ¨¡å‹ - LLM å°è©±ç›¸é—œ
class LLMChatRequest(BaseModel):
    question: str = Field(..., 
                          example="ä»€éº¼æ˜¯å½±åƒè¾¨è­˜")
    system_prompt: str = Field(default=system_prompts[0]["content"] if system_prompts else "è«‹è¼¸å…¥ç³»çµ±æç¤ºè©", 
                              description="ç³»çµ±æç¤ºè©ï¼Œå¦‚æœä¸å¡«å¯«å°‡ä½¿ç”¨é è¨­çš„æ™ºè­˜åº«è¨­å®š")

class LLMChatResponse(BaseModel):
    answer: str = Field(..., example="å˜¿ï¼Œæ¢éšªå®¶ï¼å½±åƒè¾¨è­˜å°±åƒæ˜¯è®“é›»è…¦å­¸æœƒã€çœ‹ã€æ±è¥¿çš„è¶…èƒ½åŠ›ï¼å°±åƒä½ æ•™å°æœ‹å‹èªè­˜å‹•ç‰©ä¸€æ¨£ï¼Œæˆ‘å€‘æ•™é›»è…¦èªè­˜åœ–ç‰‡ä¸­çš„å…§å®¹ã€‚æƒ³åƒä¸€ä¸‹ï¼Œå¦‚æœé›»è…¦èƒ½èªå‡ºç…§ç‰‡è£¡æ˜¯ä¸€éš»è²“ã€ä¸€æœµèŠ±ï¼Œæˆ–è€…ä¸€å€‹è˜‹æœï¼Œé‚£ä¸æ˜¯å¾ˆé…·å—ï¼ŸğŸ¤–âœ¨")


# Pydantic æ¨¡å‹ - æ¨¡çµ„ä¸€ï¼šåœ‹ç‹çš„å­é£Ÿç—‡
class GenerateRecipeTextRequest(BaseModel):
    prompt: str = Field(..., description="é£Ÿè­œç”Ÿæˆæç¤ºè©")

class GenerateRecipeTextResponse(BaseModel):
    recipe_text: str = Field(..., example="âœ¨ é­”æ³•æ£®æ—çš„å½©è™¹æ°´æœæ²™æ‹‰ âœ¨\n\né€™é“èœå°±åƒæ£®æ—ç²¾éˆçš„é­”æ³•ç››å®´ï¼æˆ‘å€‘éœ€è¦ï¼š\n\nğŸ ç´…è˜‹æœ - åˆ‡æˆå°æ˜Ÿæ˜Ÿå½¢ç‹€\nğŸŠ æ©˜å­ - å‰æˆå°æœˆç‰™\nğŸ‡ è‘¡è„ - åƒçç ä¸€æ¨£é–ƒäº®\nğŸ¥ å¥‡ç•°æœ - åˆ‡æˆå°åœ“ç‰‡\n\nèª¿å‘³é­”æ³•ï¼š\nğŸ¯ èœ‚èœœ - æ£®æ—çš„ç”œèœœç²¾è¯\nğŸ‹ æª¸æª¬æ± - æ¸…æ–°çš„é­”æ³•\nğŸŒ¿ è–„è·è‘‰ - æ£®æ—çš„é¦™æ°£\n\nåšæ³•ï¼š\n1. å°‡æ‰€æœ‰æ°´æœæ´—æ·¨ï¼Œåˆ‡æˆå¯æ„›çš„å½¢ç‹€\n2. è¼•è¼•æ··åˆï¼Œä¸è¦ç ´å£æ°´æœçš„å®Œæ•´æ€§\n3. æ·‹ä¸Šèœ‚èœœå’Œæª¸æª¬æ±çš„é­”æ³•çµ„åˆ\n4. æœ€å¾Œé»ç¶´æ–°é®®çš„è–„è·è‘‰\n\né€™é“æ²™æ‹‰ä¸åƒ…ç¾å‘³ï¼Œé‚„èƒ½è®“åœ‹ç‹æƒ³èµ·æ£®æ—çš„å¿«æ¨‚æ™‚å…‰ï¼ğŸŒˆ")

class GenerateRecipeImageRequest(BaseModel):
    prompt: str = Field(..., example="å®®ä¿é›ä¸",description="åœ–ç‰‡ç”Ÿæˆæç¤ºè©")

class GenerateRecipeImageResponse(BaseModel):
    image_url: str = Field(..., example="https://ai-odyssey-backend-rbzz.onrender.com/static/images/d1b094d315f4.png")
    prompt: str = Field(..., example="å¤§ä¾¿")
    enhanced_prompt: str = Field(..., example="Beautiful, appetizing food photography: å¤§ä¾¿. High quality, professional food image, safe for all audiences, no inappropriate content.")
    model_used: str = Field(..., example="dall-e-3")
    image_size: str = Field(..., example="1024x1024")
    generation_time: str = Field(..., example="2024-01-15T10:30:45.123456")
    generation_date: str = Field(..., example="2024-01-15")
    generation_timestamp: float = Field(..., example=1705311045.123456)
    file_info: Dict[str, Any] = Field(..., example={
        "original_filename": "d1b094d315f4.png",
        "file_path": "static/images/d1b094d315f4.png",
        "full_url": "https://ai-odyssey-backend-rbzz.onrender.com/static/images/d1b094d315f4.png"
    })
    
class GenerateCustomImageResponse(BaseModel):
    image_url: str = Field(..., example="https://ai-odyssey-backend-rbzz.onrender.com/static/images/d1b094d315f4.png")
    prompt: str = Field(..., example="æä¹…æ©ç©¿è‘—ç´…è‰²è¤²è¤²ï¼Œæ‰‹æ‹¿åå­—æ¶ï¼Œå†·å‚²é€€åŸºä½¬ï¼Œå¯«å¯¦ç•«é¢¨ï¼Œé«˜æ¸…")
    model_used: str = Field(..., example="dall-e-3")
    image_size: str = Field(..., example="1024x1024")
    generation_time: str = Field(..., example="2024-01-15T10:30:45.123456")
    generation_date: str = Field(..., example="2024-01-15")
    generation_timestamp: float = Field(..., example=1705311045.123456)
    file_info: Dict[str, Any] = Field(..., example={
        "original_filename": "d1b094d315f4.png",
        "file_path": "static/images/d1b094d315f4.png",
        "full_url": "https://ai-odyssey-backend-rbzz.onrender.com/static/images/d1b094d315f4.png"
    })
    
class GenerateCustomImageRequest(BaseModel):
    prompt: str = Field(..., example="æä¹…æ©ç©¿è‘—ç´…è‰²è¤²è¤²ï¼Œæ‰‹æ‹¿åå­—æ¶ï¼Œå†·å‚²é€€åŸºä½¬ï¼Œå¯«å¯¦ç•«é¢¨ï¼Œé«˜æ¸…", description="å®¢è£½åŒ–åœ–ç‰‡ç”Ÿæˆ")
    

# Pydantic æ¨¡å‹ - é£Ÿç‰©åœ–ç‰‡åˆ†æç›¸é—œ
class FoodImageAnalysisRequest(BaseModel):
    image_hash: str = Field(..., description="åœ–ç‰‡12ä½æ•¸hash", example="a0f7cfb81fbf.png")
    dish_expect: Optional[str] = Field(default="æˆ‘æœŸå¾…é€™æ˜¯ä¸€é“è‰²é¦™å‘³ä¿±å…¨ã€ç‡Ÿé¤Šå‡è¡¡ã€æ“ºç›¤ç²¾ç¾çš„ç¾é£Ÿ", description="å°é€™é“èœçš„æœŸå¾…æè¿°ï¼Œå¦‚æœä¸å¡«å¯«å°‡ä½¿ç”¨é è¨­æœŸå¾…")
    

class FoodImageAnalysisResponse(BaseModel):
    analysis: str = Field(..., description="Gemini å°é£Ÿç‰©çš„è©³ç´°è©•èª")
    score: int = Field(..., description="é£Ÿç‰©è©•åˆ† (0-100åˆ†)", ge=0 , le=100)
    model_used: str = Field(..., description="ä½¿ç”¨çš„æ¨¡å‹")
    image_path: str = Field(..., description="åˆ†æçš„åœ–ç‰‡è·¯å¾‘")
    prompt: str = Field(..., description="ä½¿ç”¨çš„æç¤ºè©")
    dish_expect: str = Field(..., description="é¡§å®¢å°é€™é“èœçš„æœŸå¾…æè¿°")
    full_response_text: str = Field(..., description="Gemini çš„å®Œæ•´å›æ‡‰æ–‡å­—")


# Pydantic æ¨¡å‹ - æ¨¡çµ„äºŒï¼šæ± å¡˜è£¡é¢éŠ€é¾é­šå’Œå³éƒ­é­šçš„è¾¨è­˜
class ImageInfo(BaseModel):
    name: str
    images: List[str]

class TrainingRequest(BaseModel):
    train_dataset: List[ImageInfo]
    
class PredictionRequest(BaseModel):
    image_path: str = Field(..., description="è¦é€²è¡Œé æ¸¬çš„åœ–ç‰‡åœ¨ä¼ºæœå™¨ä¸Šçš„ç›¸å°è·¯å¾‘")


# Pydantic æ¨¡å‹ - AI English Writing Teacher å°ˆæ¡ˆ
class ImageData(BaseModel):
    data: str = Field(..., description="base64ç·¨ç¢¼çš„åœ–ç‰‡æ•¸æ“š")
    mimeType: str = Field(..., description="åœ–ç‰‡MIMEé¡å‹")

class OCRRequest(BaseModel):
    images: List[ImageData] = Field(..., description="åœ–ç‰‡åˆ—è¡¨")
    system_prompt: str = Field(..., description="ç³»çµ±æç¤ºè©")

class TopicOCRResponse(BaseModel):
    topic: str = Field(..., description="ä½œæ–‡çš„ä¸»é¡Œæˆ–å•é¡Œ")
    requirements: str = Field(..., description="é¡Œç›®è¦æ±‚")
    score: str = Field(..., description="åˆ†æ•¸æˆ–ä½”æ¯”")

class EssayOCRResponse(BaseModel):
    recognized_text: str = Field(..., description="è¾¨è­˜å‡ºçš„å®Œæ•´è‹±æ–‡ä½œæ–‡æ–‡å­—")

# ä½œæ–‡æ‰¹æ”¹ç›¸é—œ
class TopicInfo(BaseModel):
    topic: str = Field(..., description="ä½œæ–‡é¡Œç›®")
    requirements: str = Field(..., description="é¡Œç›®è¦æ±‚")
    score: int = Field(..., description="åˆ†æ•¸")

class CorrectionRequest(BaseModel):
    essay_text: str = Field(..., description="å­¸ç”Ÿçš„è‹±æ–‡ä½œæ–‡å…§å®¹")
    topic_info: TopicInfo = Field(..., description="é¡Œç›®è³‡è¨Š")
    system_prompt: str = Field(..., description="ç³»çµ±æç¤ºè©")

class ScoreDetail(BaseModel):
    score: float = Field(..., description="åˆ†æ•¸")
    comment: str = Field(..., description="è©•èª")

class FeedbackItem(BaseModel):
    type: str = Field(..., description="éŒ¯èª¤é¡å‹")
    original: str = Field(..., description="åŸå§‹éŒ¯èª¤")
    suggestion: str = Field(..., description="å»ºè­°ä¿®æ­£")
    explanation: str = Field(..., description="è§£é‡‹èªªæ˜")

class CorrectionResponse(BaseModel):
    scores: Dict[str, ScoreDetail] = Field(..., description="å„é …è©•åˆ†")
    total_score: float = Field(..., description="ç¸½åˆ†")
    detailed_feedback: List[FeedbackItem] = Field(..., description="è©³ç´°å›é¥‹")
    overall_comment: str = Field(..., description="æ•´é«”è©•èª")
    rewritten_essay: str = Field(..., description="æ”¹å¯«å¾Œçš„ç¯„æ–‡")

# è¬›ç¾©ç”Ÿæˆç›¸é—œ
class HandoutRequest(BaseModel):
    correction_data: Dict[str, List[FeedbackItem]] = Field(..., description="æ‰¹æ”¹è³‡æ–™")
    system_prompt: str = Field(..., description="ç³»çµ±æç¤ºè©")

class HandoutResponse(BaseModel):
    handout_content: str = Field(..., description="ç”Ÿæˆçš„è¬›ç¾©å…§å®¹")

# ç·´ç¿’é¡Œç”Ÿæˆç›¸é—œ
class PracticeRequest(BaseModel):
    correction_data: Dict[str, List[FeedbackItem]] = Field(..., description="æ‰¹æ”¹è³‡æ–™")
    num_questions: int = Field(..., description="é¡Œç›®æ•¸é‡")
    num_versions: int = Field(..., description="ç‰ˆæœ¬æ•¸é‡")
    system_prompt: str = Field(..., description="ç³»çµ±æç¤ºè©")

class PracticeQuestion(BaseModel):
    question: str = Field(..., description="é¡Œç›®å…§å®¹")
    options: List[str] = Field(..., description="é¸é …")

class PracticeAnswer(BaseModel):
    answer: str = Field(..., description="ç­”æ¡ˆ")
    explanation: str = Field(..., description="ç­”æ¡ˆè§£é‡‹")

class PracticeVersion(BaseModel):
    title: str = Field(..., description="ç‰ˆæœ¬æ¨™é¡Œ")
    questions: List[PracticeQuestion] = Field(..., description="é¡Œç›®åˆ—è¡¨")
    answers: List[PracticeAnswer] = Field(..., description="ç­”æ¡ˆåˆ—è¡¨")

class PracticeResponse(BaseModel):
    versions: List[PracticeVersion] = Field(..., description="ç·´ç¿’é¡Œç‰ˆæœ¬")

# é€šç”¨å›æ‡‰æ ¼å¼
class AIWritingTeacherResponse(BaseModel):
    success: bool = Field(..., description="æ˜¯å¦æˆåŠŸ")
    data: Optional[Dict[str, Any]] = Field(None, description="å›æ‡‰è³‡æ–™")
    error: Optional[Dict[str, Any]] = Field(None, description="éŒ¯èª¤è³‡è¨Š")

class SuccessResponse(BaseModel):
    status: str = "success"
    data: Dict[str, Any]

class ErrorResponse(BaseModel):
    status: str = "error"
    message: str

# å·¥å…·å‡½æ•¸
def create_access_token(data: dict, expires_delta: Optional[timedelta] = None):
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.now(timezone.utc) + expires_delta
    else:
        expire = datetime.now(timezone.utc) + timedelta(minutes=15)
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt

def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)):
    try:
        token = credentials.credentials
        
        # å…ˆæª¢æŸ¥ token æ˜¯å¦åœ¨é»‘åå–®ä¸­
        if db_manager.is_token_blacklisted(token):
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Token å·²è¢«æ’¤éŠ·",
                headers={"WWW-Authenticate": "Bearer"},
            )
        
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        username: str = payload.get("sub")
        if username is None:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="ç„¡æ•ˆçš„èªè­‰æ†‘è­‰",
                headers={"WWW-Authenticate": "Bearer"},
            )
        
        # å¾è³‡æ–™åº«é©—è­‰ä½¿ç”¨è€…
        user = db_manager.get_user_by_username(username)
        if not user:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="ä½¿ç”¨è€…ä¸å­˜åœ¨",
                headers={"WWW-Authenticate": "Bearer"},
            )
        
        # æª¢æŸ¥æœƒè©±æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
        if not db_manager.is_session_valid(token):
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="æœƒè©±å·²éæœŸæˆ–å·²è¢«ç™»å‡º",
                headers={"WWW-Authenticate": "Bearer"},
            )
        
        return username
    except jwt.PyJWTError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="ç„¡æ•ˆçš„èªè­‰æ†‘è­‰",
            headers={"WWW-Authenticate": "Bearer"},
        )

async def get_api_key():
    """å–å¾— API Key"""
    if not API_KEY:
        raise HTTPException(
            status_code=500,
            detail="API Key æœªè¨­å®šï¼Œè«‹è¨­å®š NCHC_API_KEY ç’°å¢ƒè®Šæ•¸"
        )
    return API_KEY

async def get_openai_client():
    """å–å¾— OpenAI å®¢æˆ¶ç«¯"""
    if not OPENAI_API_KEY:
        raise HTTPException(
            status_code=500,
            detail="OpenAI API Key æœªè¨­å®šï¼Œè«‹è¨­å®š OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸"
        )
    return openai_client


async def download_and_save_image(image_url: str, prompt: str) -> str:
    """ä¸‹è¼‰åœ–ç‰‡ä¸¦ä¿å­˜åˆ°æœ¬åœ°ï¼Œè¿”å›æœ¬åœ°æª”æ¡ˆè·¯å¾‘"""
    try:
        # ç”Ÿæˆéš¨æ©Ÿ hash å€¼
        timestamp = str(datetime.now(timezone.utc).timestamp())
        random_salt = str(random.randint(1000, 9999))
        hash_input = f"{prompt}{timestamp}{random_salt}"
        file_hash = hashlib.md5(hash_input.encode()).hexdigest()[:12]
        
        # æª”æ¡ˆåç¨±
        filename = f"{file_hash}.png"
        filepath = os.path.join(STATIC_IMAGES_DIR, filename)
        
        # ä¸‹è¼‰åœ–ç‰‡
        async with httpx.AsyncClient() as client:
            response = await client.get(image_url, timeout=30.0)
            response.raise_for_status()
            
            # ä¿å­˜åœ–ç‰‡åˆ°æœ¬åœ°
            async with aiofiles.open(filepath, 'wb') as f:
                await f.write(response.content)
        
        logger.info(f"åœ–ç‰‡å·²ä¿å­˜åˆ°: {filepath}")
        return filename
        
    except Exception as e:
        logger.error(f"ä¸‹è¼‰åœ–ç‰‡å¤±æ•—: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ä¸‹è¼‰åœ–ç‰‡å¤±æ•—: {str(e)}"
        )

# API ç«¯é»

@app.get("/")
async def root():
    """æ ¹è·¯å¾‘"""
    return {
        "message": "AI Odyssey Backend API",
        "version": "2.0.0",
        "docs": "/docs"
    }

@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥ç«¯é»"""
    return {"status": "healthy", "api_key_configured": bool(API_KEY)}

# 1. å¸³è™Ÿèˆ‡èªè­‰ (Authentication)

@app.post("/auth/register", status_code=status.HTTP_201_CREATED)
async def register(user_data: UserRegister):
    """ä½¿ç”¨è€…è¨»å†Š"""
    try:
        # ä½¿ç”¨è³‡æ–™åº«ç®¡ç†å™¨å‰µå»ºä½¿ç”¨è€…
        user = db_manager.create_user(
            username=user_data.username,
            password=user_data.password,
            initial_money=0
        )
        
        return {
            "message": "è¨»å†ŠæˆåŠŸï¼",
            "user": {
                "id": user["id"],
                "username": user["username"],
                "money": user["money"]
            }
        }
        
    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except Exception as e:
        logger.error(f"è¨»å†Šå¤±æ•—: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="è¨»å†Šéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
        )

@app.post("/auth/login")
async def login(user_data: UserLogin):
    """ä½¿ç”¨è€…ç™»å…¥"""
    try:
        # ä½¿ç”¨è³‡æ–™åº«ç®¡ç†å™¨é©—è­‰ä½¿ç”¨è€…
        user = db_manager.verify_user(user_data.username, user_data.password)
        
        if not user:
            # ç‚ºäº†å®‰å…¨æ€§ï¼Œä¸å€åˆ†å¸³è™Ÿä¸å­˜åœ¨å’Œå¯†ç¢¼éŒ¯èª¤
            # ä½†æä¾›æ›´å‹å–„çš„éŒ¯èª¤è¨Šæ¯
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="ç™»å…¥å¤±æ•—ï¼šè«‹æª¢æŸ¥æ‚¨çš„å¸³è™Ÿåç¨±å’Œå¯†ç¢¼æ˜¯å¦æ­£ç¢ºã€‚å¦‚æœå¿˜è¨˜å¯†ç¢¼ï¼Œè«‹è¯ç¹«ç®¡ç†å“¡ã€‚",
                headers={"WWW-Authenticate": "Bearer"}
            )
        
        # å»ºç«‹ JWT token
        access_token_expires = timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
        access_token = create_access_token(
            data={"sub": user_data.username}, expires_delta=access_token_expires
        )
        
        # å‰µå»ºè³‡æ–™åº«æœƒè©±è¨˜éŒ„
        expires_at = datetime.now(timezone.utc) + access_token_expires
        db_manager.create_session(user["id"], access_token, expires_at)
        
        # è¨˜éŒ„æˆåŠŸç™»å…¥
        logger.info(f"ä½¿ç”¨è€… {user_data.username} ç™»å…¥æˆåŠŸ")
        
        return {
            "message": "ç™»å…¥æˆåŠŸï¼",
            "access_token": access_token,
            "token_type": "bearer",
            "user": {
                "id": user["id"],
                "username": user["username"],
                "money": user["money"]
            }
        }
        
    except ValueError as e:
        # è™•ç†ç‰¹å®šçš„æ¥­å‹™é‚è¼¯éŒ¯èª¤ï¼ˆå¦‚å¸³è™Ÿè¢«åœç”¨ï¼‰
        error_message = str(e)
        if "å¸³è™Ÿå·²è¢«åœç”¨" in error_message:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="å¸³è™Ÿå·²è¢«åœç”¨ï¼Œè«‹è¯ç¹«ç®¡ç†å“¡ã€‚"
            )
        else:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=error_message
            )
    except HTTPException:
        # é‡æ–°æ‹‹å‡º HTTP ç•°å¸¸
        raise
    except Exception as e:
        # è¨˜éŒ„è©³ç´°éŒ¯èª¤è³‡è¨Š
        logger.error(f"ç™»å…¥éç¨‹ä¸­ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="ç™»å…¥éç¨‹ä¸­ç™¼ç”Ÿç³»çµ±éŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚å¦‚æœå•é¡ŒæŒçºŒç™¼ç”Ÿï¼Œè«‹è¯ç¹«æŠ€è¡“æ”¯æ´ã€‚"
        )

@app.get("/users/me", response_model=SuccessResponse)
async def get_current_user(username: str = Depends(verify_token)):
    """ç²å–ç•¶å‰ä½¿ç”¨è€…è³‡è¨Š"""
    try:
        user = db_manager.get_user_by_username(username)
        if not user:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ä½¿ç”¨è€…ä¸å­˜åœ¨"
            )
        
        return SuccessResponse(data={
            "user": {
                "id": user["id"],
                "username": user["username"],
                "money": user["money"],
                "created_at": user["created_at"],
                "last_login": user["last_login"]
            }
        })
        
    except Exception as e:
        logger.error(f"ç²å–ä½¿ç”¨è€…è³‡è¨Šå¤±æ•—: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="ç²å–ä½¿ç”¨è€…è³‡è¨Šå¤±æ•—"
        )

@app.post("/auth/logout")
async def logout(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """ä½¿ç”¨è€…ç™»å‡º"""
    try:
        # ä½¿æœƒè©±ç„¡æ•ˆ
        token = credentials.credentials
        
        # å…ˆæª¢æŸ¥ token æ˜¯å¦æœ‰æ•ˆ
        if not db_manager.is_session_valid(token):
            return {"message": "æœƒè©±å·²éæœŸæˆ–ä¸å­˜åœ¨"}
        
        # æ’¤éŠ· token
        if db_manager.invalidate_session(token):
            logger.info(f"ä½¿ç”¨è€…ç™»å‡ºæˆåŠŸï¼Œtoken: {token[:20]}...")
            return {"message": "ç™»å‡ºæˆåŠŸï¼"}
        else:
            logger.warning(f"ç™»å‡ºæ™‚ token ç„¡æ•ˆ: {token[:20]}...")
            return {"message": "æœƒè©±å·²éæœŸæˆ–ä¸å­˜åœ¨"}
            
    except Exception as e:
        logger.error(f"ç™»å‡ºå¤±æ•—: {e}")
        # å³ä½¿å¤±æ•—ä¹Ÿè¦å˜—è©¦æ’¤éŠ· token
        try:
            token = credentials.credentials
            db_manager.invalidate_session(token)
        except:
            pass
        return {"message": "ç™»å‡ºæˆåŠŸï¼"}  # å³ä½¿å¤±æ•—ä¹Ÿå›å‚³æˆåŠŸï¼Œé¿å…å‰ç«¯éŒ¯èª¤

@app.post("/llmchat", response_model=LLMChatResponse)
async def chat_with_llm(
    request: LLMChatRequest,
    username: str = Depends(verify_token),      
    api_key: str = Depends(get_api_key)
):
    """èˆ‡ LLM é€²è¡Œå°è©±ï¼Œä½¿ç”¨ gpt-oss-120b æ¨¡å‹ï¼Œtemp 0.4ï¼Œmax_tokens 2000ï¼Œä½¿ç”¨system_promptä½œç‚ºç³»çµ±æç¤ºè©ï¼ˆå¦‚æœä¸å¡«å¯«å°‡ä½¿ç”¨é è¨­çš„æ™ºè­˜åº«è¨­å®šï¼‰ï¼Œä½¿ç”¨questionä½œç‚ºä½¿ç”¨è€…å•é¡Œ"""
    try:
        # å»ºç«‹è¨Šæ¯åˆ—è¡¨
        messages = [
            {
                "role": "system",
                "content": request.system_prompt
            },
            {
                "role": "user",
                "content": request.question
            }
        ]
        
        # æº–å‚™è«‹æ±‚
        chat_request = {
            "model": "gpt-oss-120b",
            "messages": messages,
            "temperature": 0.4,
            "max_tokens": 2000
        }
        
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{NCHC_API_BASE_URL}/chat/completions",
                headers={
                    "x-api-key": api_key,
                    "Content-Type": "application/json"
                },
                json=chat_request,
                timeout=60.0
            )
            
            if response.status_code != 200:
                logger.error(f"NCHC API éŒ¯èª¤: {response.status_code} - {response.text}")
                raise HTTPException(
                    status_code=response.status_code,
                    detail=f"NCHC API éŒ¯èª¤: {response.text}"
                )
            
            result = response.json()
            
            # æå–å›æ‡‰å…§å®¹
            if result.get("choices") and len(result["choices"]) > 0:
                answer = result["choices"][0]["message"]["content"]
            else:
                answer = "æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•å›ç­”é€™å€‹å•é¡Œã€‚"
            
            return LLMChatResponse(answer=answer)
            
    except httpx.TimeoutException:
        logger.error("è«‹æ±‚è¶…æ™‚")
        raise HTTPException(status_code=408, detail="è«‹æ±‚è¶…æ™‚")
    except httpx.RequestError as e:
        logger.error(f"è«‹æ±‚éŒ¯èª¤: {e}")
        raise HTTPException(status_code=500, detail=f"è«‹æ±‚éŒ¯èª¤: {str(e)}")
    except Exception as e:
        logger.error(f"æœªé æœŸéŒ¯èª¤: {e}")
        raise HTTPException(status_code=500, detail=f"æœªé æœŸéŒ¯èª¤: {str(e)}")

# 3. æ¨¡çµ„ä¸€ï¼šåœ‹ç‹çš„å­é£Ÿç—‡ (Generative AI)

@app.post("/module1/generate-recipe-text", response_model=GenerateRecipeTextResponse)
async def generate_recipe_text(
    request: GenerateRecipeTextRequest,
    username: str = Depends(verify_token),
    api_key: str = Depends(get_api_key)
):
    """æ ¹æ“šç©å®¶è¼¸å…¥çš„æç¤ºè© (Prompt)ï¼Œç”Ÿæˆèœè‰²çš„æ–‡å­—æè¿°ã€‚"""
    try:
        # å»ºç«‹è¨Šæ¯åˆ—è¡¨
        messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„å»šå¸«å’Œç¾é£Ÿä½œå®¶ã€‚è«‹æ ¹æ“šä½¿ç”¨è€…çš„è¦æ±‚ï¼Œå‰µé€ å‡ºå¯Œæœ‰å‰µæ„å’Œæƒ³åƒåŠ›çš„é£Ÿè­œæè¿°ã€‚æè¿°è¦ç”Ÿå‹•æœ‰è¶£ï¼Œç¬¦åˆç«¥è©±æ•…äº‹çš„é¢¨æ ¼ã€‚"
            },
            {
                "role": "user",
                "content": request.prompt
            }
        ]
        
        # æº–å‚™è«‹æ±‚
        chat_request = {
            "model": "gpt-oss-120b",
            "messages": messages,
            "temperature": 0.8,
            "max_tokens": 1500
        }
        
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{NCHC_API_BASE_URL}/chat/completions",
                headers={
                    "x-api-key": api_key,
                    "Content-Type": "application/json"
                },
                json=chat_request,
                timeout=60.0
            )
            
            if response.status_code != 200:
                logger.error(f"NCHC API éŒ¯èª¤: {response.status_code} - {response.text}")
                raise HTTPException(
                    status_code=response.status_code,
                    detail=f"NCHC API éŒ¯èª¤: {response.text}"
                )
            
            result = response.json()
            
            # æå–å›æ‡‰å…§å®¹
            if result.get("choices") and len(result["choices"]) > 0:
                recipe_text = result["choices"][0]["message"]["content"]
            else:
                recipe_text = "æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•ç”Ÿæˆé£Ÿè­œæè¿°ã€‚"
            
            return GenerateRecipeTextResponse(recipe_text=recipe_text)
            
    except httpx.TimeoutException:
        logger.error("è«‹æ±‚è¶…æ™‚")
        raise HTTPException(status_code=408, detail="è«‹æ±‚è¶…æ™‚")
    except httpx.RequestError as e:
        logger.error(f"è«‹æ±‚éŒ¯èª¤: {e}")
        raise HTTPException(status_code=500, detail=f"è«‹æ±‚éŒ¯èª¤: {str(e)}")
    except Exception as e:
        logger.error(f"æœªé æœŸéŒ¯èª¤: {e}")
        raise HTTPException(status_code=500, detail=f"æœªé æœŸéŒ¯èª¤: {str(e)}")


@app.post("/generate-custom-image", response_model=GenerateCustomImageResponse)
async def generate_custom_image(
    request: GenerateCustomImageRequest,
    http_request: Request,
    username: str = Depends(verify_token),
    client: OpenAI = Depends(get_openai_client)
):
    """å®Œå…¨å®¢è£½åŒ–åœ–ç‰‡ç”Ÿæˆï¼Œä½¿ç”¨ DALL-E 3 æ¨¡å‹"""
    try:      
        # ä½¿ç”¨ DALL-E ç”Ÿæˆåœ–ç‰‡
        response = client.images.generate(
            model="dall-e-3",
            prompt=request.prompt,
            n=1,
            size="1024x1024"
        )
        
        # ç›´æ¥å–å¾—åœ–ç‰‡ URL
        if response.data and len(response.data) > 0:
            image_url = response.data[0].url
        else:
            raise HTTPException(
                status_code=500,
                detail="åœ–ç‰‡ç”Ÿæˆå¤±æ•—"
            )
        
        # ä¸‹è¼‰ä¸¦ä¿å­˜åœ–ç‰‡åˆ°æœ¬åœ°
        filename = await download_and_save_image(image_url, request.prompt)
        
        # è¿”å›æœ¬åœ°åœ–ç‰‡ URL
        base_url = str(http_request.base_url).rstrip('/')
        local_image_url = f"{base_url}/static/images/{filename}"
        
        # è¨˜éŒ„ç”Ÿæˆæ™‚é–“
        generation_time = datetime.now(timezone.utc)
        
        return GenerateCustomImageResponse(
            image_url=local_image_url,
            prompt=request.prompt,
            model_used="dall-e-3",
            image_size="1024x1024",
            generation_time=generation_time.isoformat(),
            generation_date=generation_time.strftime("%Y-%m-%d"),
            generation_timestamp=generation_time.timestamp(),
            file_info={
                "original_filename": filename,
                "file_path": f"static/images/{filename}",
                "full_url": local_image_url
            }
        )
        
    except Exception as e:
        error_msg = str(e)
        logger.error(f"åœ–ç‰‡ç”ŸæˆéŒ¯èª¤: {error_msg}")
        
        # è™•ç†ç‰¹å®šçš„ OpenAI éŒ¯èª¤
        if "content_policy_violation" in error_msg:
            raise HTTPException(
                status_code=400,
                detail="æç¤ºè©å…§å®¹é•åå®‰å…¨æ”¿ç­–ï¼Œè«‹ä½¿ç”¨æ›´é©ç•¶çš„æè¿°ã€‚"
            )
        elif "safety_system" in error_msg:
            raise HTTPException(
                status_code=400,
                detail="æç¤ºè©è¢«å®‰å…¨ç³»çµ±æ‹’çµ•ï¼Œè«‹é¿å…ä½¿ç”¨å¯èƒ½ä¸ç•¶çš„è©å½™ã€‚"
            )
        elif "400" in error_msg:
            raise HTTPException(
                status_code=400,
                detail="è«‹æ±‚æ ¼å¼éŒ¯èª¤ï¼Œè«‹æª¢æŸ¥æç¤ºè©å…§å®¹ã€‚å»ºè­°ï¼šä½¿ç”¨æ¸…æ™°ã€å…·é«”çš„é£Ÿç‰©æè¿°ã€‚"
            )
        else:
            raise HTTPException(
                status_code=500,
                detail=f"åœ–ç‰‡ç”ŸæˆéŒ¯èª¤: {error_msg}"
            )


@app.post("/module1/generate-recipe-image", response_model=GenerateRecipeImageResponse)
async def generate_recipe_image(
    request: GenerateRecipeImageRequest,
    http_request: Request,
    username: str = Depends(verify_token),
    client: OpenAI = Depends(get_openai_client)
):
    """å°‡é£Ÿè­œæ–‡å­—æè¿°å‚³çµ¦å¾Œç«¯ï¼Œç”Ÿæˆå°æ‡‰çš„èœè‰²åœ–ç‰‡ã€‚"""
    try:
        # å„ªåŒ–æç¤ºè©ï¼Œå¢åŠ å®‰å…¨æ€§å’Œå…·é«”æ€§
        enhanced_prompt = f"Beautiful, appetizing food photography: {request.prompt}. High quality, professional food image."
        
        # ä½¿ç”¨ DALL-E ç”Ÿæˆåœ–ç‰‡
        response = client.images.generate(
            model="dall-e-3",
            prompt=enhanced_prompt,
            n=1,
            size="1024x1024"
        )
        
        # ç›´æ¥å–å¾—åœ–ç‰‡ URL
        if response.data and len(response.data) > 0:
            image_url = response.data[0].url
        else:
            raise HTTPException(
                status_code=500,
                detail="åœ–ç‰‡ç”Ÿæˆå¤±æ•—"
            )
        
        # ä¸‹è¼‰ä¸¦ä¿å­˜åœ–ç‰‡åˆ°æœ¬åœ°
        filename = await download_and_save_image(image_url, request.prompt)
        
        # è¿”å›æœ¬åœ°åœ–ç‰‡ URL
        base_url = str(http_request.base_url).rstrip('/')
        local_image_url = f"{base_url}/static/images/{filename}"
        
        # è¨˜éŒ„ç”Ÿæˆæ™‚é–“
        generation_time = datetime.now(timezone.utc)
        
        return GenerateRecipeImageResponse(
            image_url=local_image_url,
            prompt=request.prompt,
            enhanced_prompt=enhanced_prompt,
            model_used="dall-e-3",
            image_size="1024x1024",
            generation_time=generation_time.isoformat(),
            generation_date=generation_time.strftime("%Y-%m-%d"),
            generation_timestamp=generation_time.timestamp(),
            file_info={
                "original_filename": filename,
                "file_path": f"static/images/{filename}",
                "full_url": local_image_url
            }
        )
        
    except Exception as e:
        error_msg = str(e)
        logger.error(f"åœ–ç‰‡ç”ŸæˆéŒ¯èª¤: {error_msg}")
        
        # è™•ç†ç‰¹å®šçš„ OpenAI éŒ¯èª¤
        if "content_policy_violation" in error_msg:
            raise HTTPException(
                status_code=400,
                detail="æç¤ºè©å…§å®¹é•åå®‰å…¨æ”¿ç­–ï¼Œè«‹ä½¿ç”¨æ›´é©ç•¶çš„æè¿°ã€‚å»ºè­°ï¼šæè¿°å…·é«”çš„é£Ÿæã€çƒ¹é£ªæ–¹å¼ã€èœè‰²å¤–è§€ç­‰ã€‚"
            )
        elif "safety_system" in error_msg:
            raise HTTPException(
                status_code=400,
                detail="æç¤ºè©è¢«å®‰å…¨ç³»çµ±æ‹’çµ•ï¼Œè«‹é¿å…ä½¿ç”¨å¯èƒ½ä¸ç•¶çš„è©å½™ã€‚å»ºè­°ï¼šå°ˆæ³¨æ–¼é£Ÿç‰©çš„æ­£é¢æè¿°ã€‚"
            )
        elif "400" in error_msg:
            raise HTTPException(
                status_code=400,
                detail="è«‹æ±‚æ ¼å¼éŒ¯èª¤ï¼Œè«‹æª¢æŸ¥æç¤ºè©å…§å®¹ã€‚å»ºè­°ï¼šä½¿ç”¨æ¸…æ™°ã€å…·é«”çš„é£Ÿç‰©æè¿°ã€‚"
            )
        else:
            raise HTTPException(
                status_code=500,
                detail=f"åœ–ç‰‡ç”ŸæˆéŒ¯èª¤: {error_msg}"
            )

@app.post("/module1/analyze-food-image", response_model=FoodImageAnalysisResponse)
async def analyze_food_image(
    request: FoodImageAnalysisRequest,
    username: str = Depends(verify_token)
):
    """ä½¿ç”¨ Gemini åˆ†æé£Ÿç‰©åœ–ç‰‡ä¸¦çµ¦å‡ºè©•èª"""
    try:
        # æª¢æŸ¥åœ–ç‰‡æ˜¯å¦å­˜åœ¨
        image_path = os.path.join(STATIC_IMAGES_DIR, f"{request.image_hash}")
        if not os.path.exists(image_path):
            raise HTTPException(
                status_code=404,
                detail=f"æ‰¾ä¸åˆ°åœ–ç‰‡: {image_path}"
            )
        
        # è®€å–åœ–ç‰‡æ–‡ä»¶
        with open(image_path, 'rb') as f:
            image_bytes = f.read()
        
        # ä½¿ç”¨ Gemini åˆ†æåœ–ç‰‡
        from google.genai import types
        
        # å‹•æ…‹ç”Ÿæˆ promptï¼Œè®“ AI ä»¥åš´æ ¼é¤å»³å»šå¸«çš„èº«ä»½ä¾†è©•åˆ†
        chef_prompt = f"""ä½ æ˜¯ä¸€ä½ç¶“é©—è±å¯Œã€è¦æ±‚åš´æ ¼çš„ç±³å…¶æ—æ˜Ÿç´šé¤å»³ä¸»å»šã€‚è«‹ä»¥å°ˆæ¥­å»šå¸«çš„çœ¼å…‰ï¼Œåš´æ ¼åˆ†æé€™å¼µé£Ÿç‰©åœ–ç‰‡ã€‚
å°é£Ÿç‰©çš„æœŸå¾…ï¼š{request.dish_expect}
è«‹æŒ‰ç…§ä»¥ä¸‹å›ºå®šæ ¼å¼å›è¦†ï¼š
SCORE: [0-100åˆ†]
(è©•åˆ†æ¨™æº–ï¼š0-59åˆ†=ä¸åˆæ ¼ï¼Œ60-70åˆ†=åŠæ ¼ï¼Œ71-85åˆ†=è‰¯å¥½ï¼Œ86-95åˆ†=å„ªç§€ï¼Œ96-100åˆ†=å®Œç¾)

ANALYSIS:
[è«‹ä»¥åš´æ ¼å»šå¸«çš„è§’åº¦ï¼Œè©³ç´°è©•èª(ä¸è¦è¶…é150å­—ï¼Œä¸è¦æ¢åˆ—å¼å›ç­”ï¼Œä¸è¦ä½¿ç”¨markdownæ ¼å¼èªæ³•å¦‚"**")ï¼ŒåŒ…æ‹¬ï¼š
1. é£Ÿç‰©åç¨±å’Œé¡å‹è­˜åˆ¥
2. å¤–è§€ã€é¡è‰²ã€æ“ºç›¤çš„å°ˆæ¥­è©•ä¼°
3. é£Ÿæé¸æ“‡åˆ†æ
4. èˆ‡é¡§å®¢æœŸå¾…çš„å°æ¯”åˆ†æ
5. æ”¹é€²å»ºè­°å’Œå°ˆæ¥­é»è©•]

è«‹ç¢ºä¿å›è¦†æ ¼å¼å®Œå…¨æŒ‰ç…§ä¸Šè¿°æ¨¡æ¿ï¼ŒSCORE å¿…é ˆæ˜¯ 0-100 çš„æ•´æ•¸åˆ†æ•¸ã€‚ä»¥åš´æ ¼çš„å°ˆæ¥­æ¨™æº–ä¾†è©•åˆ†ã€‚"""
        
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=[
                types.Part.from_bytes(
                    data=image_bytes,
                    mime_type='image/png',
                ),
                chef_prompt
            ]
        )
        
        # è§£æ AI å›è¦†ï¼Œæå–åˆ†æ•¸å’Œè©•èª
        response_text = response.text
        
        # å˜—è©¦å¾å›è¦†ä¸­æå–åˆ†æ•¸å’Œè©•èª
        score = 50  # é è¨­åˆ†æ•¸
        analysis = response_text  # é è¨­ä½¿ç”¨å®Œæ•´å›è¦†
        
        try:
            # å°‹æ‰¾ SCORE: æ¨™è¨˜
            if "SCORE:" in response_text:
                score_line = response_text.split("SCORE:")[1].split("\n")[0].strip()
                # æå–æ•¸å­—
                import re
                score_match = re.search(r'\d+', score_line)
                if score_match:
                    score = int(score_match.group())
                    # ç¢ºä¿åˆ†æ•¸åœ¨ 0-100 ç¯„åœå…§
                    score = max(0, min(100, score))
            
            # å°‹æ‰¾ ANALYSIS: æ¨™è¨˜
            if "ANALYSIS:" in response_text:
                analysis_parts = response_text.split("ANALYSIS:")
                if len(analysis_parts) > 1:
                    analysis = analysis_parts[1].strip()
                else:
                    analysis = response_text
            else:
                # å¦‚æœæ²’æœ‰æ‰¾åˆ°æ¨™è¨˜ï¼Œå˜—è©¦æ™ºèƒ½åˆ†å‰²
                lines = response_text.split('\n')
                # è·³éå¯èƒ½åŒ…å«åˆ†æ•¸çš„å‰å¹¾è¡Œï¼Œå–å¾Œé¢çš„å…§å®¹ä½œç‚ºè©•èª
                analysis_lines = []
                for line in lines:
                    if not line.strip().startswith('SCORE:') and line.strip():
                        analysis_lines.append(line)
                if analysis_lines:
                    analysis = '\n'.join(analysis_lines).strip()
                    
        except Exception as e:
            logger.warning(f"è§£æ AI å›è¦†æ™‚å‡ºç¾å•é¡Œ: {e}ï¼Œä½¿ç”¨é è¨­å€¼")
            score = 50
            analysis = response_text
        
        return FoodImageAnalysisResponse(
            analysis=analysis,
            score=score,
            model_used="gemini-2.5-flash",
            full_response_text=response_text,
            image_path=image_path,
            prompt=chef_prompt,
            dish_expect=request.dish_expect
        )
        
    except FileNotFoundError:
        raise HTTPException(
            status_code=404,
            detail=f"åœ–ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}"
        )
    except Exception as e:
        logger.error(f"åœ–ç‰‡åˆ†æéŒ¯èª¤: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"åœ–ç‰‡åˆ†æéŒ¯èª¤: {str(e)}"
        )


# 2. æ¨¡çµ„äºŒï¼šæ± å¡˜è£¡é¢éŠ€é¾é­šå’Œå³éƒ­é­šçš„è¾¨è­˜
@app.post("/module2/train/{user_name}")
async def train_user_model(
    user_name: str, 
    request: TrainingRequest,
    current_user: str = Depends(verify_token)
):
    """è¨“ç·´ç©å®¶çš„æ¨¡å‹ï¼Œå›å‚³è¨“ç·´çµæœ"""
    # é©—è­‰ä½¿ç”¨è€…åªèƒ½è¨“ç·´è‡ªå·±çš„æ¨¡å‹
    if user_name != current_user:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="åªèƒ½è¨“ç·´è‡ªå·±çš„æ¨¡å‹"
        )
    
    if GLOBAL_MOBILENET is None:
        return {"success": False, "error": "åŸºç¤æ¨¡å‹å°šæœªæº–å‚™å°±ç·’ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"}

    # 1. ç‚ºæ­¤ä½¿ç”¨è€…å–å¾—æˆ–å‰µå»ºä¸€å€‹æ¨¡å‹ç®¡ç†å™¨å¯¦ä¾‹
    #    é€™è£¡ä½¿ç”¨å¿«å– USER_MODELS ä¾†é¿å…é‡è¤‡å‰µå»ºå°è±¡
    if user_name not in USER_MODELS:
        USER_MODELS[user_name] = ImageClassificationModel(user_name=user_name, base_model=GLOBAL_MOBILENET)
    
    model_manager = USER_MODELS[user_name]
    
    # 2. è¼‰å…¥è¨“ç·´æ•¸æ“š
    data_config = request.model_dump()
    if not model_manager.load_training_data(data_config):
        return {"success": False, "error": "è¼‰å…¥è¨“ç·´æ•¸æ“šå¤±æ•—ï¼Œè«‹æª¢æŸ¥åœ–ç‰‡è·¯å¾‘ã€‚"}
        
    # 3. åŸ·è¡Œè¨“ç·´
    result = await model_manager.train_model()
    
    # è¨“ç·´å®Œæˆå¾Œï¼Œæ›´æ–°å¿«å–ä¸­çš„æ¨¡å‹ç‹€æ…‹
    USER_MODELS[user_name] = model_manager
    
    return result

@app.post("/module2/predict/{user_name}")
async def predict_with_user_model(
    user_name: str, 
    request: PredictionRequest,
    current_user: str = Depends(verify_token)
):
    """ä½¿ç”¨ç©å®¶çš„æ¨¡å‹é æ¸¬é­šçš„ç¨®é¡ï¼Œå›å‚³é æ¸¬çµæœ"""
    # é©—è­‰ä½¿ç”¨è€…åªèƒ½ä½¿ç”¨è‡ªå·±çš„æ¨¡å‹
    if user_name != current_user:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="åªèƒ½ä½¿ç”¨è‡ªå·±çš„æ¨¡å‹"
        )
    
    if GLOBAL_MOBILENET is None:
        return {"success": False, "error": "åŸºç¤æ¨¡å‹å°šæœªæº–å‚™å°±ç·’ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"}

    # 1. å–å¾—æ­¤ä½¿ç”¨è€…çš„æ¨¡å‹ç®¡ç†å™¨
    #    å¦‚æœä¸åœ¨å¿«å–ä¸­ï¼Œå°±å‰µå»ºä¸€å€‹æ–°çš„ã€‚__init__ æœƒè‡ªå‹•å˜—è©¦å¾ç¡¬ç¢Ÿè¼‰å…¥å·²ä¿å­˜çš„æ¨¡å‹
    if user_name not in USER_MODELS:
        USER_MODELS[user_name] = ImageClassificationModel(user_name=user_name, base_model=GLOBAL_MOBILENET)

    model_manager = USER_MODELS[user_name]

    # 2. æª¢æŸ¥æ¨¡å‹æ˜¯å¦å·²è¨“ç·´
    if not model_manager.is_trained:
        return {"success": False, "error": f"ä½¿ç”¨è€… {user_name} çš„æ¨¡å‹å°šæœªè¨“ç·´ï¼Œè«‹å…ˆèª¿ç”¨è¨“ç·´ APIã€‚"}
    
    # 3. åŸ·è¡Œé æ¸¬
    prediction = model_manager.predict_image(request.image_path)
    return prediction
   

# ============================================================================
# AI English Writing Teacher å°ˆæ¡ˆ API ç«¯é»
# ============================================================================

# 1. é¡Œç›®åœ–ç‰‡è¾¨è­˜æ¥å£
@app.post("/api/ocr/topic", response_model=AIWritingTeacherResponse)
async def ocr_topic(request: OCRRequest):
    """é¡Œç›®åœ–ç‰‡è¾¨è­˜æ¥å£"""
    try:
        # æª¢æŸ¥æ˜¯å¦æœ‰åœ–ç‰‡
        if not request.images:
            return AIWritingTeacherResponse(
                success=False,
                data=None,
                error={
                    "code": "INVALID_REQUEST",
                    "message": "è«‹æä¾›åœ–ç‰‡",
                    "details": "images æ¬„ä½ä¸èƒ½ç‚ºç©º"
                }
            )
        
        # ä½¿ç”¨ Gemini é€²è¡Œåœ–ç‰‡è¾¨è­˜
        from google.genai import types
        
        # é…ç½® Gemini å®¢æˆ¶ç«¯
        gemini_api_key = os.getenv("AI_ENGLISH_WRITING_TEACHER")
        if not gemini_api_key:
            return AIWritingTeacherResponse(
                success=False,
                data=None,
                error={
                    "code": "INTERNAL_ERROR",
                    "message": "Gemini API Key æœªè¨­å®š",
                    "details": "è«‹è¨­å®š AI_ENGLISH_WRITING_TEACHER ç’°å¢ƒè®Šæ•¸"
                }
            )
        
        client = genai.Client(api_key=gemini_api_key)
        
        # è™•ç†ç¬¬ä¸€å¼µåœ–ç‰‡ï¼ˆé¡Œç›®è¾¨è­˜é€šå¸¸åªéœ€è¦ä¸€å¼µï¼‰
        image_data = request.images[0]
        
        # å°‡ base64 è½‰æ›ç‚º bytes
        import base64
        try:
            image_bytes = base64.b64decode(image_data.data)
        except Exception as e:
            return AIWritingTeacherResponse(
                success=False,
                data=None,
                error={
                    "code": "INVALID_IMAGE_FORMAT",
                    "message": "åœ–ç‰‡æ ¼å¼éŒ¯èª¤",
                    "details": f"base64 è§£ç¢¼å¤±æ•—: {str(e)}"
                }
            )
        
        # ä½¿ç”¨ Gemini é€²è¡Œåœ–ç‰‡è¾¨è­˜
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=[
                types.Part.from_bytes(
                    data=image_bytes,
                    mime_type=image_data.mimeType,
                ),
                request.system_prompt
            ]
        )
        
        # è§£æå›æ‡‰ï¼ˆå‡è¨­ AI æœƒè¿”å› JSON æ ¼å¼ï¼‰
        response_text = response.text
        if "```json" in response_text:
            json_start = response_text.find("```json") + 7
            json_end = response_text.find("```", json_start)
            if json_end != -1:
                json_str = response_text[json_start:json_end].strip()
                result = json.loads(json_str)
            else:
                result = {"topic": "ç„¡æ³•è§£æ", "requirements": "ç„¡æ³•è§£æ", "score": "ç„¡æ³•è§£æ"}
        else:
            # å¦‚æœæ²’æœ‰ JSON æ¨™è¨˜ï¼Œå˜—è©¦ç›´æ¥è§£æ
            result = json.loads(response_text)

        return AIWritingTeacherResponse(
            success=True,
            data=result,
            error=None
        )
        
    except json.JSONDecodeError:
        # å¦‚æœ JSON è§£æå¤±æ•—ï¼Œä½¿ç”¨é è¨­æ ¼å¼
        result = {
            "topic": "åœ–ç‰‡è¾¨è­˜å®Œæˆï¼Œä½†æ ¼å¼è§£æå¤±æ•—",
            "requirements": "è«‹æª¢æŸ¥ AI å›æ‡‰æ ¼å¼",
            "score": "ç„¡æ³•ç¢ºå®š"
        }
        return AIWritingTeacherResponse(success=True, data=result, error=None)
    except Exception as e:
        logger.error(f"é¡Œç›®åœ–ç‰‡è¾¨è­˜å¤±æ•—: {e}")
        return AIWritingTeacherResponse(
            success=False,
            data=None,
            error={
                "code": "OCR_FAILED",
                "message": "åœ–ç‰‡è¾¨è­˜å¤±æ•—",
                "details": str(e)
            }
        )

# 2. æ‰‹å¯«ä½œæ–‡è¾¨è­˜æ¥å£
@app.post("/api/ocr/essay", response_model=AIWritingTeacherResponse)
async def ocr_essay(request: OCRRequest):
    """æ‰‹å¯«ä½œæ–‡è¾¨è­˜æ¥å£"""
    try:
        # æª¢æŸ¥æ˜¯å¦æœ‰åœ–ç‰‡
        if not request.images:
            return AIWritingTeacherResponse(
                success=False,
                data=None,
                error={
                    "code": "INVALID_REQUEST",
                    "message": "è«‹æä¾›åœ–ç‰‡",
                    "details": "images æ¬„ä½ä¸èƒ½ç‚ºç©º"
                }
            )
        
        # ä½¿ç”¨ Gemini é€²è¡Œåœ–ç‰‡è¾¨è­˜
        from google.genai import types
        
        # é…ç½® Gemini å®¢æˆ¶ç«¯
        gemini_api_key = os.getenv("AI_ENGLISH_WRITING_TEACHER")
        if not gemini_api_key:
            return AIWritingTeacherResponse(
                success=False,
                data=None,
                error={
                    "code": "INTERNAL_ERROR",
                    "message": "Gemini API Key æœªè¨­å®š",
                    "details": "è«‹è¨­å®š AI_ENGLISH_WRITING_TEACHER ç’°å¢ƒè®Šæ•¸"
                }
            )
        
        client = genai.Client(api_key=gemini_api_key)
        
        # è™•ç†æ‰€æœ‰åœ–ç‰‡ï¼ˆæ‰‹å¯«ä½œæ–‡å¯èƒ½éœ€è¦å¤šå¼µåœ–ç‰‡ï¼‰
        all_texts = []
        
        for image_data in request.images:
            # å°‡ base64 è½‰æ›ç‚º bytes
            import base64
            try:
                image_bytes = base64.b64decode(image_data.data)
            except Exception as e:
                return AIWritingTeacherResponse(
                    success=False,
                    data=None,
                    error={
                        "code": "INVALID_IMAGE_FORMAT",
                        "message": "åœ–ç‰‡æ ¼å¼éŒ¯èª¤",
                        "details": f"base64 è§£ç¢¼å¤±æ•—: {str(e)}"
                    }
                )
            
            # ä½¿ç”¨ Gemini é€²è¡Œåœ–ç‰‡è¾¨è­˜
            response = client.models.generate_content(
                model="gemini-2.5-flash",
                contents=[
                    types.Part.from_bytes(
                        data=image_bytes,
                        mime_type=image_data.mimeType,
                    ),
                    request.system_prompt
                ]
            )
            
            all_texts.append(response.text)
        
        # åˆä½µæ‰€æœ‰è¾¨è­˜å‡ºçš„æ–‡å­—
        combined_text = " ".join(all_texts)
        
        return AIWritingTeacherResponse(
            success=True,
            data={"recognized_text": combined_text},
            error=None
        )
        
    except Exception as e:
        logger.error(f"æ‰‹å¯«ä½œæ–‡è¾¨è­˜å¤±æ•—: {e}")
        return AIWritingTeacherResponse(
            success=False,
            data=None,
            error={
                "code": "OCR_FAILED",
                "message": "æ‰‹å¯«ä½œæ–‡è¾¨è­˜å¤±æ•—",
                "details": str(e)
            }
        )

# 3. ä½œæ–‡æ‰¹æ”¹æ¥å£
@app.post("/api/ai/correction", response_model=AIWritingTeacherResponse)
async def correct_essay(request: CorrectionRequest):
    """ä½œæ–‡æ‰¹æ”¹æ¥å£"""
    try:
        # ä½¿ç”¨ gpt-oss-120b é€²è¡Œä½œæ–‡æ‰¹æ”¹
        nchc_api_key = os.getenv("NCHC_API_KEY")
        if not nchc_api_key:
            return AIWritingTeacherResponse(
                success=False,
                data=None,
                error={
                    "code": "INTERNAL_ERROR",
                    "message": "NCHC API Key æœªè¨­å®š",
                    "details": "è«‹è¨­å®š NCHC_API_KEY ç’°å¢ƒè®Šæ•¸"
                }
            )
        
        # æº–å‚™è«‹æ±‚
        messages = [
            {
                "role": "system",
                "content": request.system_prompt
            },
            {
                "role": "user",
                "content": f"é¡Œç›®è³‡è¨Šï¼š{request.topic_info.topic}\nè¦æ±‚ï¼š{request.topic_info.requirements}\nåˆ†æ•¸ï¼š{request.topic_info.score}\n\nå­¸ç”Ÿä½œæ–‡ï¼š{request.essay_text}"
            }
        ]
        
        chat_request = {
            "model": "gpt-oss-120b",
            "messages": messages,
            "temperature": 0.3,
            "max_tokens": 20000
        }
        
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{NCHC_API_BASE_URL}/chat/completions",
                headers={
                    "x-api-key": nchc_api_key,
                    "Content-Type": "application/json"
                },
                json=chat_request,
                timeout=60.0
            )
            
            if response.status_code != 200:
                return AIWritingTeacherResponse(
                    success=False,
                    data=None,
                    error={
                        "code": "AI_GENERATION_FAILED",
                        "message": "AI ç”Ÿæˆå¤±æ•—",
                        "details": f"NCHC API éŒ¯èª¤: {response.text}"
                    }
                )
            
            result = response.json()
            
            # æå–å›æ‡‰å…§å®¹
            if result.get("choices") and len(result["choices"]) > 0:
                ai_response = result["choices"][0]["message"]["content"]
            else:
                return AIWritingTeacherResponse(
                    success=False,
                    data=None,
                    error={
                        "code": "AI_GENERATION_FAILED",
                        "message": "AI å›æ‡‰æ ¼å¼éŒ¯èª¤",
                        "details": "ç„¡æ³•æå– AI å›æ‡‰å…§å®¹"
                    }
                )
            
            # å˜—è©¦è§£æ AI å›æ‡‰ï¼ˆå‡è¨­æœƒè¿”å›çµæ§‹åŒ–æ•¸æ“šï¼‰
            try:
                import json
                if "```json" in ai_response:
                    json_start = ai_response.find("```json") + 7
                    json_end = ai_response.find("```", json_start)
                    if json_end != -1:
                        json_str = ai_response[json_start:json_end].strip()
                        correction_data = json.loads(json_str)
                    else:
                        correction_data = {"error": "ç„¡æ³•è§£æ JSON æ ¼å¼"}
                else:
                    correction_data = {"raw_response": ai_response}
                
                return AIWritingTeacherResponse(
                    success=True,
                    data=correction_data,
                    error=None
                )
                
            except json.JSONDecodeError:
                return AIWritingTeacherResponse(
                    success=True,
                    data={"raw_response": ai_response},
                    error=None
                )
                
    except Exception as e:
        logger.error(f"ä½œæ–‡æ‰¹æ”¹å¤±æ•—: {e}")
        return AIWritingTeacherResponse(
            success=False,
            data=None,
            error={
                "code": "AI_GENERATION_FAILED",
                "message": "ä½œæ–‡æ‰¹æ”¹å¤±æ•—",
                "details": str(e)
            }
        )

# 4. è¬›ç¾©ç”Ÿæˆæ¥å£
@app.post("/api/ai/handout", response_model=AIWritingTeacherResponse)
async def generate_handout(request: HandoutRequest):
    """è¬›ç¾©ç”Ÿæˆæ¥å£"""
    try:
        # ä½¿ç”¨ gpt-oss-120b ç”Ÿæˆè¬›ç¾©
        nchc_api_key = os.getenv("NCHC_API_KEY")
        if not nchc_api_key:
            return AIWritingTeacherResponse(
                success=False,
                data=None,
                error={
                    "code": "INTERNAL_ERROR",
                    "message": "NCHC API Key æœªè¨­å®š",
                    "details": "è«‹è¨­å®š NCHC_API_KEY ç’°å¢ƒè®Šæ•¸"
                }
            )
        
        # æº–å‚™è«‹æ±‚
        messages = [
            {
                "role": "system",
                "content": request.system_prompt
            },
            {
                "role": "user",
                "content": f"æ‰¹æ”¹è³‡æ–™ï¼š{json.dumps(jsonable_encoder(request.correction_data), ensure_ascii=False)}"
            }
        ]
        
        chat_request = {
            "model": "gpt-oss-120b",
            "messages": messages,
            "temperature": 0.4,
            "max_tokens": 20000
        }
        
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{NCHC_API_BASE_URL}/chat/completions",
                headers={
                    "x-api-key": nchc_api_key,
                    "Content-Type": "application/json"
                },
                json=chat_request,
                timeout=60.0
            )
            
            if response.status_code != 200:
                return AIWritingTeacherResponse(
                    success=False,
                    data=None,
                    error={
                        "code": "AI_GENERATION_FAILED",
                        "message": "è¬›ç¾©ç”Ÿæˆå¤±æ•—",
                        "details": f"NCHC API éŒ¯èª¤: {response.text}"
                    }
                )
            
            result = response.json()
            
            # æå–å›æ‡‰å…§å®¹
            if result.get("choices") and len(result["choices"]) > 0:
                handout_content = result["choices"][0]["message"]["content"]
            else:
                return AIWritingTeacherResponse(
                    success=False,
                    data=None,
                    error={
                        "code": "AI_GENERATION_FAILED",
                        "message": "è¬›ç¾©ç”Ÿæˆå¤±æ•—",
                        "details": "ç„¡æ³•æå– AI å›æ‡‰å…§å®¹"
                    }
                )
            
            return AIWritingTeacherResponse(
                success=True,
                data={"handout_content": handout_content},
                error=None
            )
                
    except Exception as e:
        logger.error(f"è¬›ç¾©ç”Ÿæˆå¤±æ•—: {e}")
        return AIWritingTeacherResponse(
            success=False,
            data=None,
            error={
                "code": "AI_GENERATION_FAILED",
                "message": "è¬›ç¾©ç”Ÿæˆå¤±æ•—",
                "details": str(e)
            }
        )

# 5. ç·´ç¿’é¡Œç”Ÿæˆæ¥å£
@app.post("/api/ai/practice", response_model=AIWritingTeacherResponse)
async def generate_practice_questions(request: PracticeRequest):
    """ç·´ç¿’é¡Œç”Ÿæˆæ¥å£"""
    try:
        # ä½¿ç”¨ gpt-oss-120b ç”Ÿæˆç·´ç¿’é¡Œ
        nchc_api_key = os.getenv("NCHC_API_KEY")
        if not nchc_api_key:
            return AIWritingTeacherResponse(
                success=False,
                data=None,
                error={
                    "code": "INTERNAL_ERROR",
                    "message": "NCHC API Key æœªè¨­å®š",
                    "details": "è«‹è¨­å®š NCHC_API_KEY ç’°å¢ƒè®Šæ•¸"
                }
            )
        
        # æº–å‚™è«‹æ±‚
        messages = [
            {
                "role": "system",
                "content": request.system_prompt
            },
            {
                "role": "user",
                "content": f"æ‰¹æ”¹è³‡æ–™ï¼š{json.dumps(jsonable_encoder(request.correction_data), ensure_ascii=False)}\né¡Œç›®æ•¸é‡ï¼š{request.num_questions}\nç‰ˆæœ¬æ•¸é‡ï¼š{request.num_versions}"
            }
        ]
        
        chat_request = {
            "model": "gpt-oss-120b",
            "messages": messages,
            "temperature": 0.5,
            "max_tokens": 20000
        }
        
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{NCHC_API_BASE_URL}/chat/completions",
                headers={
                    "x-api-key": nchc_api_key,
                    "Content-Type": "application/json"
                },
                json=chat_request,
                timeout=60.0
            )
            
            if response.status_code != 200:
                return AIWritingTeacherResponse(
                    success=False,
                    data=None,
                    error={
                        "code": "AI_GENERATION_FAILED",
                        "message": "ç·´ç¿’é¡Œç”Ÿæˆå¤±æ•—",
                        "details": f"NCHC API éŒ¯èª¤: {response.text}"
                    }
                )
            
            result = response.json()
            
            # æå–å›æ‡‰å…§å®¹
            if result.get("choices") and len(result["choices"]) > 0:
                practice_content = result["choices"][0]["message"]["content"]
            else:
                return AIWritingTeacherResponse(
                    success=False,
                    data=None,
                    error={
                        "code": "AI_GENERATION_FAILED",
                        "message": "ç·´ç¿’é¡Œç”Ÿæˆå¤±æ•—",
                        "details": "ç„¡æ³•æå– AI å›æ‡‰å…§å®¹"
                    }
                )
            
            # å˜—è©¦è§£æ AI å›æ‡‰
            if "```json" in practice_content:
                json_start = practice_content.find("```json") + 7
                json_end = practice_content.find("```", json_start)
                if json_end != -1:
                    json_str = practice_content[json_start:json_end].strip()
                    practice_data = json.loads(json_str)
                else:
                    practice_data = {"raw_response": practice_content}
            else:
                practice_data = {"raw_response": practice_content}
            
            return AIWritingTeacherResponse(
                success=True,
                data=practice_data,
                error=None
            )
                
    except json.JSONDecodeError:
        return AIWritingTeacherResponse(
            success=True,
            data={"raw_response": "AI å›æ‡‰çš„ JSON è§£æå¤±æ•—"},
            error=None
        )
    except Exception as e:
        logger.error(f"ç·´ç¿’é¡Œç”Ÿæˆå¤±æ•—: {e}")
        return AIWritingTeacherResponse(
            success=False,
            data=None,
            error={
                "code": "AI_GENERATION_FAILED",
                "message": "ç·´ç¿’é¡Œç”Ÿæˆå¤±æ•—",
                "details": str(e)
            }
        )

@app.get("/system-prompts")
async def get_system_prompts():
    """å–å¾—å¯ç”¨çš„ system prompts åˆ—è¡¨"""
    return {
        "prompts": system_prompts
    }

@app.get("/users/{username}/statistics")
async def get_user_statistics(username: str, current_user: str = Depends(verify_token)):
    """ç²å–ä½¿ç”¨è€…çµ±è¨ˆè³‡è¨Šï¼ˆéœ€è¦ç™»å…¥ï¼‰"""
    try:
        # æª¢æŸ¥æ˜¯å¦ç‚ºç•¶å‰ä½¿ç”¨è€…æˆ–ç®¡ç†å“¡
        if username != current_user:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="åªèƒ½æŸ¥çœ‹è‡ªå·±çš„çµ±è¨ˆè³‡è¨Š"
            )
        
        user = db_manager.get_user_by_username(username)
        if not user:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ä½¿ç”¨è€…ä¸å­˜åœ¨"
            )
        
        statistics = db_manager.get_user_statistics(user["id"])
        return SuccessResponse(data=statistics)
        
    except Exception as e:
        logger.error(f"ç²å–ä½¿ç”¨è€…çµ±è¨ˆè³‡è¨Šå¤±æ•—: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="ç²å–çµ±è¨ˆè³‡è¨Šå¤±æ•—"
        )

@app.get("/models")
async def list_models():
    """å–å¾—å¯ç”¨æ¨¡å‹åˆ—è¡¨ - å‘å¾Œç›¸å®¹"""
    return {
        "models": [
            "Llama-4-Maverick-17B-128E-Instruct-FP8",
            "gpt-oss-120b",
            "gemini-2.5-flash",
            "dall-e-3",
            "gemini-embedding-001"
        ]
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
